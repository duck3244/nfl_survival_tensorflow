"""
ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ëª¨ë“ˆ
í•™ìŠµ, í‰ê°€, ê²€ì¦ ê¸°ëŠ¥ ì œê³µ
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, KFold
from lifelines.utils import concordance_index
from typing import Tuple, Optional, Dict
import matplotlib.pyplot as plt
import seaborn as sns


class ModelTrainer:
    """ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self, model, random_state: int = 42):
        """
        Parameters:
        -----------
        model : DeepSurv
            í•™ìŠµí•  ëª¨ë¸
        random_state : int
            ë‚œìˆ˜ ì‹œë“œ
        """
        self.model = model
        self.random_state = random_state
        self.train_c_index = None
        self.test_c_index = None
        self.history = None
        
    def train_test_split_data(self,
                               X: np.ndarray,
                               y_event: np.ndarray,
                               y_time: np.ndarray,
                               test_size: float = 0.2) -> Tuple:
        """
        í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
        
        Parameters:
        -----------
        X : np.ndarray
            íŠ¹ì§• í–‰ë ¬
        y_event : np.ndarray
            ì´ë²¤íŠ¸ ë°œìƒ ì—¬ë¶€
        y_time : np.ndarray
            ìƒì¡´ ì‹œê°„
        test_size : float
            í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
        
        Returns:
        --------
        tuple
            (X_train, X_test, y_event_train, y_event_test, 
             y_time_train, y_time_test)
        """
        return train_test_split(
            X, y_event, y_time,
            test_size=test_size,
            random_state=self.random_state
        )
    
    def train(self,
              X_train: np.ndarray,
              y_event_train: np.ndarray,
              y_time_train: np.ndarray,
              validation_split: float = 0.2,
              epochs: int = 100,
              batch_size: int = 32,
              verbose: int = 1):
        """
        ëª¨ë¸ í•™ìŠµ
        
        Parameters:
        -----------
        X_train : np.ndarray
            í•™ìŠµ íŠ¹ì§•
        y_event_train : np.ndarray
            í•™ìŠµ ì´ë²¤íŠ¸
        y_time_train : np.ndarray
            í•™ìŠµ ì‹œê°„
        validation_split : float
            ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
        epochs : int
            ì—í­ ìˆ˜
        batch_size : int
            ë°°ì¹˜ í¬ê¸°
        verbose : int
            ì¶œë ¥ ë ˆë²¨
        
        Returns:
        --------
        history
            í•™ìŠµ ì´ë ¥
        """
        print("=" * 70)
        print("ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        print("=" * 70)
        print(f"í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ")
        print(f"ê²€ì¦ ë¹„ìœ¨: {validation_split}")
        print(f"ì—í­: {epochs}, ë°°ì¹˜ í¬ê¸°: {batch_size}")
        
        self.history = self.model.fit(
            X_train, y_event_train, y_time_train,
            validation_split=validation_split,
            epochs=epochs,
            batch_size=batch_size,
            verbose=verbose
        )
        
        print("\nâœ“ í•™ìŠµ ì™„ë£Œ!")
        
        return self.history
    
    def evaluate(self,
                 X_train: np.ndarray,
                 y_event_train: np.ndarray,
                 y_time_train: np.ndarray,
                 X_test: np.ndarray,
                 y_event_test: np.ndarray,
                 y_time_test: np.ndarray) -> Dict[str, float]:
        """
        ëª¨ë¸ í‰ê°€ (C-index ê³„ì‚°)
        
        Parameters:
        -----------
        X_train, X_test : np.ndarray
            í•™ìŠµ/í…ŒìŠ¤íŠ¸ íŠ¹ì§•
        y_event_train, y_event_test : np.ndarray
            í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì´ë²¤íŠ¸
        y_time_train, y_time_test : np.ndarray
            í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì‹œê°„
        
        Returns:
        --------
        metrics : dict
            í‰ê°€ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
        """
        print("\n" + "=" * 70)
        print("ëª¨ë¸ í‰ê°€")
        print("=" * 70)
        
        # ìœ„í—˜ ì ìˆ˜ ì˜ˆì¸¡
        train_risk = self.model.predict_risk(X_train)
        test_risk = self.model.predict_risk(X_test)

        # C-index ê³„ì‚°
        self.train_c_index = concordance_index(y_time_train, -train_risk, y_event_train)
        self.test_c_index = concordance_index(y_time_test, -test_risk, y_event_test)

        metrics = {
            'train_c_index': self.train_c_index,
            'test_c_index': self.test_c_index,
            'train_samples': len(X_train),
            'test_samples': len(X_test)
        }

        print(f"\nğŸ“Š ì„±ëŠ¥ ì§€í‘œ:")
        print(f"  Training C-index:   {self.train_c_index:.4f}")
        print(f"  Testing C-index:    {self.test_c_index:.4f}")
        print(f"  Overfitting Gap:    {abs(self.train_c_index - self.test_c_index):.4f}")

        # ì„±ëŠ¥ í‰ê°€
        if self.test_c_index > 0.7:
            print("  â­ ìš°ìˆ˜í•œ ì„±ëŠ¥!")
        elif self.test_c_index > 0.6:
            print("  âœ… ì–‘í˜¸í•œ ì„±ëŠ¥!")
        elif self.test_c_index > 0.55:
            print("  ğŸ“Š ë³´í†µ ì„±ëŠ¥")
        else:
            print("  âš ï¸  ì„±ëŠ¥ ê°œì„  í•„ìš”")

        return metrics

    def cross_validate(self,
                       X: np.ndarray,
                       y_event: np.ndarray,
                       y_time: np.ndarray,
                       n_splits: int = 5,
                       epochs: int = 50,
                       verbose: int = 0) -> Dict[str, any]:
        """
        K-Fold êµì°¨ ê²€ì¦

        Parameters:
        -----------
        X : np.ndarray
            ì „ì²´ íŠ¹ì§• í–‰ë ¬
        y_event : np.ndarray
            ì „ì²´ ì´ë²¤íŠ¸
        y_time : np.ndarray
            ì „ì²´ ì‹œê°„
        n_splits : int
            Fold ìˆ˜
        epochs : int
            ê° Foldë‹¹ ì—í­ ìˆ˜
        verbose : int
            ì¶œë ¥ ë ˆë²¨

        Returns:
        --------
        cv_results : dict
            êµì°¨ ê²€ì¦ ê²°ê³¼
        """
        print("\n" + "=" * 70)
        print(f"{n_splits}-Fold êµì°¨ ê²€ì¦")
        print("=" * 70)

        kfold = KFold(n_splits=n_splits, shuffle=True, random_state=self.random_state)
        c_indices = []

        for fold, (train_idx, val_idx) in enumerate(kfold.split(X), 1):
            print(f"\nFold {fold}/{n_splits}...")

            X_train, X_val = X[train_idx], X[val_idx]
            y_event_train, y_event_val = y_event[train_idx], y_event[val_idx]
            y_time_train, y_time_val = y_time[train_idx], y_time[val_idx]

            # ìƒˆ ëª¨ë¸ ìƒì„± (ê° Foldë§ˆë‹¤)
            from model_architecture import DeepSurv
            config = self.model.get_config()
            fold_model = DeepSurv(**config)
            fold_model.compile()

            # í•™ìŠµ
            fold_model.fit(
                X_train, y_event_train, y_time_train,
                validation_split=0.2,
                epochs=epochs,
                batch_size=32,
                verbose=verbose
            )

            # í‰ê°€
            risk_scores = fold_model.predict_risk(X_val)
            c_index = concordance_index(y_time_val, -risk_scores, y_event_val)
            c_indices.append(c_index)

            print(f"  C-index: {c_index:.4f}")

        # ê²°ê³¼ ìš”ì•½
        cv_results = {
            'c_indices': c_indices,
            'mean_c_index': np.mean(c_indices),
            'std_c_index': np.std(c_indices),
            'min_c_index': np.min(c_indices),
            'max_c_index': np.max(c_indices)
        }

        print("\n" + "-" * 70)
        print(f"ğŸ“Š êµì°¨ ê²€ì¦ ê²°ê³¼:")
        print(f"  í‰ê·  C-index:  {cv_results['mean_c_index']:.4f} Â± {cv_results['std_c_index']:.4f}")
        print(f"  ìµœì†Œ C-index:  {cv_results['min_c_index']:.4f}")
        print(f"  ìµœëŒ€ C-index:  {cv_results['max_c_index']:.4f}")

        if cv_results['std_c_index'] < 0.03:
            print("  âœ… ë§¤ìš° ì•ˆì •ì ì¸ ëª¨ë¸")
        elif cv_results['std_c_index'] < 0.05:
            print("  ğŸ‘ ì•ˆì •ì ì¸ ëª¨ë¸")
        else:
            print("  âš ï¸  ë¶ˆì•ˆì •í•œ ëª¨ë¸ - í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • í•„ìš”")

        return cv_results

    def plot_training_history(self, save_path: Optional[str] = None):
        """í•™ìŠµ ê³¡ì„  ì‹œê°í™”"""
        if self.history is None:
            print("âŒ í•™ìŠµ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
            return

        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        # Loss ê³¡ì„ 
        axes[0].plot(self.history.history['loss'],
                    label='Training Loss', linewidth=2, color='#3498db')
        axes[0].plot(self.history.history['val_loss'],
                    label='Validation Loss', linewidth=2, color='#e74c3c')
        axes[0].set_xlabel('Epoch', fontsize=12)
        axes[0].set_ylabel('Loss', fontsize=12)
        axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')
        axes[0].legend(fontsize=11)
        axes[0].grid(alpha=0.3)

        # MAE ê³¡ì„ 
        axes[1].plot(self.history.history['mae'],
                    label='Training MAE', linewidth=2, color='#3498db')
        axes[1].plot(self.history.history['val_mae'],
                    label='Validation MAE', linewidth=2, color='#e74c3c')
        axes[1].set_xlabel('Epoch', fontsize=12)
        axes[1].set_ylabel('MAE', fontsize=12)
        axes[1].set_title('Training and Validation MAE', fontsize=14, fontweight='bold')
        axes[1].legend(fontsize=11)
        axes[1].grid(alpha=0.3)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ“ í•™ìŠµ ê³¡ì„  ì €ì¥: {save_path}")

        plt.show()

    def plot_cv_results(self, cv_results: Dict, save_path: Optional[str] = None):
        """êµì°¨ ê²€ì¦ ê²°ê³¼ ì‹œê°í™”"""
        c_indices = cv_results['c_indices']
        n_splits = len(c_indices)

        fig, ax = plt.subplots(figsize=(10, 6))

        # C-index í”Œë¡¯
        ax.plot(range(1, n_splits + 1), c_indices,
               marker='o', linewidth=2.5, markersize=10,
               color='#e74c3c', label='C-index')

        # í‰ê· ì„ 
        mean_c = cv_results['mean_c_index']
        ax.axhline(y=mean_c, color='#3498db',
                  linestyle='--', linewidth=2,
                  label=f'Mean: {mean_c:.4f}')

        # ì‹ ë¢°êµ¬ê°„
        std_c = cv_results['std_c_index']
        ax.fill_between(range(1, n_splits + 1),
                        mean_c - std_c,
                        mean_c + std_c,
                        alpha=0.2, color='#3498db',
                        label=f'Â±1 SD: {std_c:.4f}')

        ax.set_xlabel('Fold', fontsize=12)
        ax.set_ylabel('C-index', fontsize=12)
        ax.set_title(f'{n_splits}-Fold Cross Validation Results',
                    fontsize=14, fontweight='bold')
        ax.legend(fontsize=11)
        ax.grid(alpha=0.3)
        ax.set_xticks(range(1, n_splits + 1))
        ax.set_ylim([min(c_indices) - 0.05, max(c_indices) + 0.05])

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ“ êµì°¨ ê²€ì¦ ê²°ê³¼ ì €ì¥: {save_path}")

        plt.show()


class EnsembleTrainer:
    """ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ í´ë˜ìŠ¤"""

    def __init__(self, n_models: int = 5, random_state: int = 42):
        """
        Parameters:
        -----------
        n_models : int
            ì•™ìƒë¸”í•  ëª¨ë¸ ìˆ˜
        random_state : int
            ë‚œìˆ˜ ì‹œë“œ
        """
        self.n_models = n_models
        self.random_state = random_state
        self.models = []

    def train_ensemble(self,
                       X: np.ndarray,
                       y_event: np.ndarray,
                       y_time: np.ndarray,
                       model_config: Dict,
                       epochs: int = 50,
                       verbose: int = 0):
        """
        ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ

        Parameters:
        -----------
        X : np.ndarray
            íŠ¹ì§• í–‰ë ¬
        y_event : np.ndarray
            ì´ë²¤íŠ¸
        y_time : np.ndarray
            ì‹œê°„
        model_config : dict
            ëª¨ë¸ ì„¤ì •
        epochs : int
            ì—í­ ìˆ˜
        verbose : int
            ì¶œë ¥ ë ˆë²¨
        """
        print(f"\nì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì‹œì‘ ({self.n_models}ê°œ ëª¨ë¸)")
        print("=" * 70)

        from model_architecture import DeepSurv

        for i in range(self.n_models):
            print(f"\nëª¨ë¸ {i+1}/{self.n_models} í•™ìŠµ ì¤‘...")

            # ëª¨ë¸ ìƒì„±
            model = DeepSurv(**model_config)
            model.compile(learning_rate=0.001)

            # Bootstrap ìƒ˜í”Œë§
            np.random.seed(self.random_state + i)
            indices = np.random.choice(len(X), size=len(X), replace=True)

            X_boot = X[indices]
            y_event_boot = y_event[indices]
            y_time_boot = y_time[indices]

            # í•™ìŠµ
            model.fit(X_boot, y_event_boot, y_time_boot,
                     validation_split=0.2,
                     epochs=epochs,
                     batch_size=32,
                     verbose=verbose)

            self.models.append(model)

        print(f"\nâœ“ ì•™ìƒë¸” í•™ìŠµ ì™„ë£Œ! (ì´ {len(self.models)}ê°œ ëª¨ë¸)")

    def predict_risk(self, X: np.ndarray, method: str = 'mean') -> np.ndarray:
        """
        ì•™ìƒë¸” ì˜ˆì¸¡

        Parameters:
        -----------
        X : np.ndarray
            íŠ¹ì§• í–‰ë ¬
        method : str
            ì•™ìƒë¸” ë°©ë²• ('mean', 'median')

        Returns:
        --------
        risk_scores : np.ndarray
            ì•™ìƒë¸” ìœ„í—˜ ì ìˆ˜
        """
        predictions = [model.predict_risk(X) for model in self.models]

        if method == 'mean':
            return np.mean(predictions, axis=0)
        elif method == 'median':
            return np.median(predictions, axis=0)
        else:
            raise ValueError(f"Unknown method: {method}")


def train_and_evaluate_model(X: np.ndarray,
                             y_event: np.ndarray,
                             y_time: np.ndarray,
                             model,
                             test_size: float = 0.2,
                             epochs: int = 100,
                             batch_size: int = 32,
                             plot: bool = True) -> Dict:
    """
    ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì›ìŠ¤í… í•¨ìˆ˜

    Parameters:
    -----------
    X, y_event, y_time : np.ndarray
        ë°ì´í„°
    model : DeepSurv
        í•™ìŠµí•  ëª¨ë¸
    test_size : float
        í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
    epochs : int
        ì—í­ ìˆ˜
    batch_size : int
        ë°°ì¹˜ í¬ê¸°
    plot : bool
        ê·¸ë˜í”„ ì¶œë ¥ ì—¬ë¶€

    Returns:
    --------
    results : dict
        í•™ìŠµ ë° í‰ê°€ ê²°ê³¼
    """
    trainer = ModelTrainer(model)

    # ë°ì´í„° ë¶„í• 
    X_train, X_test, y_event_train, y_event_test, y_time_train, y_time_test = \
        trainer.train_test_split_data(X, y_event, y_time, test_size=test_size)

    # í•™ìŠµ
    history = trainer.train(X_train, y_event_train, y_time_train,
                           epochs=epochs, batch_size=batch_size)

    # í‰ê°€
    metrics = trainer.evaluate(X_train, y_event_train, y_time_train,
                              X_test, y_event_test, y_time_test)

    # ì‹œê°í™”
    if plot:
        trainer.plot_training_history()

    results = {
        'model': model,
        'trainer': trainer,
        'metrics': metrics,
        'history': history,
        'data_splits': {
            'X_train': X_train,
            'X_test': X_test,
            'y_event_train': y_event_train,
            'y_event_test': y_event_test,
            'y_time_train': y_time_train,
            'y_time_test': y_time_test
        }
    }

    return results


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("=" * 70)
    print("ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    # ìƒ˜í”Œ ë°ì´í„°
    from data_preprocessing import create_sample_data, NFLDataPreprocessor

    create_sample_data(n_samples=300, output_path='test_data.csv')

    preprocessor = NFLDataPreprocessor('test_data.csv')
    X, y_event, y_time = preprocessor.get_feature_matrix()

    # ëª¨ë¸ ìƒì„±
    from model_architecture import DeepSurv

    model = DeepSurv(input_dim=3, hidden_layers=[32, 16])
    model.compile()

    # í•™ìŠµ ë° í‰ê°€
    results = train_and_evaluate_model(
        X, y_event, y_time,
        model,
        epochs=30,
        batch_size=32,
        plot=False
    )

    print(f"\nìµœì¢… í…ŒìŠ¤íŠ¸ C-index: {results['metrics']['test_c_index']:.4f}")

    # êµì°¨ ê²€ì¦ í…ŒìŠ¤íŠ¸
    print("\nêµì°¨ ê²€ì¦ í…ŒìŠ¤íŠ¸...")
    trainer = results['trainer']
    cv_results = trainer.cross_validate(X, y_event, y_time, n_splits=3, epochs=20, verbose=0)

    print("\nâœ“ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
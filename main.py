"""
ë©”ì¸ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸
ì „ì²´ í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” í†µí•© ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import argparse
import warnings
warnings.filterwarnings('ignore')

# ëª¨ë“ˆ ì„í¬íŠ¸
from data_preprocessing import NFLDataPreprocessor, create_sample_data
from model_architecture import DeepSurv, create_deepsurv_model
from model_training import ModelTrainer, train_and_evaluate_model
from visualization import SurvivalVisualizer, plot_multiple_players_comparison
from prediction_utils import PlayerPredictor, FamousPlayersPredictor
from lifelines import KaplanMeierFitter
import numpy as np


def run_full_pipeline(data_path='nfl.csv',
                     model_type='standard',
                     epochs=100,
                     batch_size=32,
                     save_model=True,
                     output_dir='output'):
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    
    Parameters:
    -----------
    data_path : str
        ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    model_type : str
        ëª¨ë¸ íƒ€ì… ('standard', 'deep', 'wide', 'simple')
    epochs : int
        í•™ìŠµ ì—í­ ìˆ˜
    batch_size : int
        ë°°ì¹˜ í¬ê¸°
    save_model : bool
        ëª¨ë¸ ì €ì¥ ì—¬ë¶€
    output_dir : str
        ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    print("=" * 70)
    print("NFL RUNNING BACK SURVIVAL ANALYSIS - FULL PIPELINE")
    print("=" * 70)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # ========== 1. ë°ì´í„° ì „ì²˜ë¦¬ ==========
    print("\n[STEP 1/6] ë°ì´í„° ì „ì²˜ë¦¬")
    print("-" * 70)
    
    if not os.path.exists(data_path):
        print(f"âš ï¸  ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        print("ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        create_sample_data(n_samples=500, output_path=data_path)
    
    preprocessor = NFLDataPreprocessor(data_path)
    df = preprocessor.preprocess()
    
    # íŠ¹ì§• í–‰ë ¬ ì¶”ì¶œ
    X, y_event, y_time = preprocessor.get_feature_matrix(
        feature_columns=['BMI', 'YPC', 'DrAge']
    )
    
    print(f"\nâœ“ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
    print(f"  - ìƒ˜í”Œ ìˆ˜: {len(X)}")
    print(f"  - í‰ê·  ì»¤ë¦¬ì–´: {y_time.mean():.1f} ê²½ê¸°")
    print(f"  - ì¤‘ê°„ ì»¤ë¦¬ì–´: {np.median(y_time):.1f} ê²½ê¸°")
    
    # ========== 2. ëª¨ë¸ ìƒì„± ë° ì»´íŒŒì¼ ==========
    print("\n[STEP 2/6] ëª¨ë¸ ìƒì„±")
    print("-" * 70)
    
    model = create_deepsurv_model(input_dim=3, model_type=model_type)
    model.compile(learning_rate=0.001)
    
    print(f"âœ“ {model_type.capitalize()} ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    print("\nëª¨ë¸ ì•„í‚¤í…ì²˜:")
    model.summary()
    
    # ========== 3. ëª¨ë¸ í•™ìŠµ ==========
    print("\n[STEP 3/6] ëª¨ë¸ í•™ìŠµ")
    print("-" * 70)
    
    results = train_and_evaluate_model(
        X, y_event, y_time,
        model,
        test_size=0.2,
        epochs=epochs,
        batch_size=batch_size,
        plot=False
    )
    
    trainer = results['trainer']
    metrics = results['metrics']
    
    # í•™ìŠµ ê³¡ì„  ì €ì¥
    trainer.plot_training_history(
        save_path=os.path.join(output_dir, 'training_history.png')
    )
    
    # ========== 4. ëª¨ë¸ í‰ê°€ ==========
    print("\n[STEP 4/6] ëª¨ë¸ í‰ê°€")
    print("-" * 70)
    
    print(f"\nìµœì¢… ì„±ëŠ¥:")
    print(f"  Training C-index: {metrics['train_c_index']:.4f}")
    print(f"  Testing C-index:  {metrics['test_c_index']:.4f}")
    
    # êµì°¨ ê²€ì¦
    print(f"\nêµì°¨ ê²€ì¦ ìˆ˜í–‰ ì¤‘...")
    cv_results = trainer.cross_validate(X, y_event, y_time, n_splits=5, 
                                       epochs=50, verbose=0)
    
    trainer.plot_cv_results(
        cv_results,
        save_path=os.path.join(output_dir, 'cross_validation.png')
    )
    
    # ========== 5. ì‹œê°í™” ==========
    print("\n[STEP 5/6] ê²°ê³¼ ì‹œê°í™”")
    print("-" * 70)
    
    viz = SurvivalVisualizer()
    
    # Kaplan-Meier ê³¡ì„ 
    viz.plot_kaplan_meier(
        y_time, y_event,
        save_path=os.path.join(output_dir, 'kaplan_meier.png')
    )
    
    # ìœ„í—˜ ê·¸ë£¹ë³„ KM ê³¡ì„ 
    test_risk = model.predict_risk(results['data_splits']['X_test'])
    viz.plot_km_by_risk(
        results['data_splits']['y_time_test'],
        results['data_splits']['y_event_test'],
        test_risk,
        n_groups=3,
        save_path=os.path.join(output_dir, 'km_by_risk.png')
    )
    
    # ìœ„í—˜ ì ìˆ˜ ë¶„í¬
    viz.plot_risk_distribution(
        test_risk,
        save_path=os.path.join(output_dir, 'risk_distribution.png')
    )
    
    # ========== 6. ì˜ˆì¸¡ ==========
    print("\n[STEP 6/6] ì„ ìˆ˜ ì˜ˆì¸¡")
    print("-" * 70)
    
    # Kaplan-Meier ê¸°ì¤€ ìƒì„±
    kmf = KaplanMeierFitter()
    kmf.fit(results['data_splits']['y_time_train'],
            results['data_splits']['y_event_train'])
    
    # ì˜ˆì¸¡ê¸° ìƒì„±
    predictor = PlayerPredictor(model, kmf)
    
    # ìœ ëª… ì„ ìˆ˜ ì˜ˆì¸¡
    famous = FamousPlayersPredictor(predictor)
    famous_df = famous.predict_all_famous_players()
    
    print("\nìœ ëª… NFL ëŸ¬ë‹ë°± ì˜ˆì¸¡ ê²°ê³¼ (Top 5):")
    print(famous_df[['Player', 'Predicted_Career', 'Grade']].head().to_string(index=False))
    
    # ê²°ê³¼ ì €ì¥
    famous_df.to_csv(
        os.path.join(output_dir, 'famous_players_predictions.csv'),
        index=False
    )
    
    # ê°œë³„ ì„ ìˆ˜ ì˜ˆì¸¡ ì˜ˆì‹œ
    print("\nì˜ˆì‹œ ì„ ìˆ˜ ì˜ˆì¸¡:")
    example_pred = predictor.predict_player(bmi=29.0, ypc=4.5, draft_age=21)
    report = predictor.generate_report(example_pred, "Example Player")
    print(report)
    
    # ë¦¬í¬íŠ¸ ì €ì¥
    predictor.save_report(
        example_pred,
        "Example Player",
        os.path.join(output_dir, 'example_prediction_report.txt')
    )
    
    # ========== ëª¨ë¸ ì €ì¥ ==========
    if save_model:
        print("\nëª¨ë¸ ì €ì¥ ì¤‘...")
        model.save(os.path.join(output_dir, 'deepsurv_model'))
        print(f"âœ“ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {output_dir}/deepsurv_model")
    
    # ========== ìµœì¢… ìš”ì•½ ==========
    print("\n" + "=" * 70)
    print("íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
    print("=" * 70)
    
    print(f"\nğŸ“Š ìƒì„±ëœ íŒŒì¼:")
    print(f"  ğŸ“ {output_dir}/")
    print(f"    â”œâ”€â”€ training_history.png")
    print(f"    â”œâ”€â”€ cross_validation.png")
    print(f"    â”œâ”€â”€ kaplan_meier.png")
    print(f"    â”œâ”€â”€ km_by_risk.png")
    print(f"    â”œâ”€â”€ risk_distribution.png")
    print(f"    â”œâ”€â”€ famous_players_predictions.csv")
    print(f"    â”œâ”€â”€ example_prediction_report.txt")
    if save_model:
        print(f"    â”œâ”€â”€ deepsurv_model_model.h5")
        print(f"    â””â”€â”€ deepsurv_model_scaler.pkl")
    
    print(f"\nğŸ¯ ìµœì¢… ì„±ëŠ¥:")
    print(f"  Test C-index: {metrics['test_c_index']:.4f}")
    print(f"  CV Mean C-index: {cv_results['mean_c_index']:.4f} Â± {cv_results['std_c_index']:.4f}")
    
    return {
        'model': model,
        'trainer': trainer,
        'metrics': metrics,
        'cv_results': cv_results,
        'predictor': predictor,
        'famous_df': famous_df
    }


def run_quick_demo():
    """ë¹ ë¥¸ ë°ëª¨ ì‹¤í–‰ (5ë¶„ ì´ë‚´)"""
    print("=" * 70)
    print("ë¹ ë¥¸ ë°ëª¨ ëª¨ë“œ (5ë¶„ ì™„ì„±)")
    print("=" * 70)
    
    return run_full_pipeline(
        data_path='nfl_sample.csv',
        model_type='simple',
        epochs=30,
        batch_size=32,
        save_model=False,
        output_dir='demo_output'
    )


def run_predict_mode(model_path, bmi, ypc, draft_age):
    """ì˜ˆì¸¡ ì „ìš© ëª¨ë“œ"""
    print("=" * 70)
    print("ì˜ˆì¸¡ ëª¨ë“œ")
    print("=" * 70)
    
    # ëª¨ë¸ ë¡œë“œ
    print("\nëª¨ë¸ ë¡œë”© ì¤‘...")
    model = DeepSurv(input_dim=3)
    model.load(model_path)
    print("âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    # ë”ë¯¸ KMF (ì‹¤ì œë¡œëŠ” ì €ì¥ëœ ê²ƒ ì‚¬ìš©)
    kmf = KaplanMeierFitter()
    y_dummy = np.random.exponential(60, 100)
    kmf.fit(y_dummy, np.ones(100))
    
    # ì˜ˆì¸¡
    predictor = PlayerPredictor(model, kmf)
    prediction = predictor.predict_player(bmi, ypc, draft_age)
    
    # ê²°ê³¼ ì¶œë ¥
    report = predictor.generate_report(prediction, "Your Player")
    print("\n" + report)
    
    return prediction


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='NFL Running Back Survival Analysis',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
  python main.py --mode full --data nfl.csv --epochs 100

  # ë¹ ë¥¸ ë°ëª¨
  python main.py --mode demo

  # ì„ ìˆ˜ ì˜ˆì¸¡
  python main.py --mode predict --model output/deepsurv_model --bmi 29.0 --ypc 4.5 --age 21
        """
    )
    
    parser.add_argument('--mode', type=str, default='full',
                       choices=['full', 'demo', 'predict'],
                       help='ì‹¤í–‰ ëª¨ë“œ')
    
    parser.add_argument('--data', type=str, default='nfl.csv',
                       help='ë°ì´í„° íŒŒì¼ ê²½ë¡œ')
    
    parser.add_argument('--model-type', type=str, default='standard',
                       choices=['standard', 'deep', 'wide', 'simple'],
                       help='ëª¨ë¸ íƒ€ì…')
    
    parser.add_argument('--epochs', type=int, default=100,
                       help='í•™ìŠµ ì—í­ ìˆ˜')
    
    parser.add_argument('--batch-size', type=int, default=32,
                       help='ë°°ì¹˜ í¬ê¸°')
    
    parser.add_argument('--output', type=str, default='output',
                       help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    
    parser.add_argument('--no-save', action='store_true',
                       help='ëª¨ë¸ ì €ì¥ ì•ˆí•¨')
    
    # ì˜ˆì¸¡ ëª¨ë“œ íŒŒë¼ë¯¸í„°
    parser.add_argument('--model', type=str,
                       help='ë¡œë“œí•  ëª¨ë¸ ê²½ë¡œ (ì˜ˆì¸¡ ëª¨ë“œ)')
    
    parser.add_argument('--bmi', type=float,
                       help='BMI (ì˜ˆì¸¡ ëª¨ë“œ)')
    
    parser.add_argument('--ypc', type=float,
                       help='Yards Per Carry (ì˜ˆì¸¡ ëª¨ë“œ)')
    
    parser.add_argument('--age', type=int,
                       help='Draft Age (ì˜ˆì¸¡ ëª¨ë“œ)')
    
    args = parser.parse_args()
    
    # ëª¨ë“œë³„ ì‹¤í–‰
    if args.mode == 'full':
        results = run_full_pipeline(
            data_path=args.data,
            model_type=args.model_type,
            epochs=args.epochs,
            batch_size=args.batch_size,
            save_model=not args.no_save,
            output_dir=args.output
        )
        
    elif args.mode == 'demo':
        results = run_quick_demo()
        
    elif args.mode == 'predict':
        if not all([args.model, args.bmi, args.ypc, args.age]):
            parser.error("ì˜ˆì¸¡ ëª¨ë“œëŠ” --model, --bmi, --ypc, --age í•„ìˆ˜")
        
        results = run_predict_mode(
            args.model,
            args.bmi,
            args.ypc,
            args.age
        )
    
    return results


if __name__ == "__main__":
    try:
        results = main()
        print("\nâœ… í”„ë¡œê·¸ë¨ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        sys.exit(0)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
